{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1fffbf-81b5-4afa-b03a-88640819c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24dfcb02-10c0-465e-ab8a-c165b4bc8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   electric_powerDemand  gnss_altitude  gnss_latitude  gnss_longitude  \\\n",
      "0                 0.008     440.702911       0.826673        0.149307   \n",
      "1                 0.008     440.702911       0.826673        0.149307   \n",
      "2                 0.008     440.702911       0.826673        0.149307   \n",
      "3                 0.008     440.702911       0.826673        0.149307   \n",
      "4                 0.008     440.702911       0.826673        0.149307   \n",
      "\n",
      "   status_doorIsOpen  status_gridIsAvailable  temperature_ambient  \\\n",
      "0                0.0                     1.0           293.149994   \n",
      "1                0.0                     1.0           293.149994   \n",
      "2                0.0                     1.0           293.149994   \n",
      "3                0.0                     1.0           293.149994   \n",
      "4                0.0                     1.0           293.149994   \n",
      "\n",
      "   traction_brakePressure  traction_tractionForce  busNumber  ...  \\\n",
      "0              249.167007                     0.0        183  ...   \n",
      "1              249.167007                     0.0        183  ...   \n",
      "2              248.033005                     0.0        183  ...   \n",
      "3              249.167007                     0.0        183  ...   \n",
      "4              248.651001                     0.0        183  ...   \n",
      "\n",
      "  itcs_numberOfPassengers_central itcs_numberOfPassengers_range  \\\n",
      "0                       33.114578                            70   \n",
      "1                       33.114578                            70   \n",
      "2                       33.114578                            70   \n",
      "3                       33.114578                            70   \n",
      "4                       33.114578                            70   \n",
      "\n",
      "   itcs_numberOfPassengers_spread  is_stationary  \\\n",
      "0                        2.113873              1   \n",
      "1                        2.113873              1   \n",
      "2                        2.113873              1   \n",
      "3                        2.113873              1   \n",
      "4                        2.113873              1   \n",
      "\n",
      "   gnss_course_stationary_zero_flag  gnss_course_stationary_mean  \\\n",
      "0                                 0                      2.00174   \n",
      "1                                 0                      2.00174   \n",
      "2                                 0                      2.00174   \n",
      "3                                 0                      2.00174   \n",
      "4                                 0                      2.00174   \n",
      "\n",
      "   gnss_course_stationary_var  gnss_course_sin  gnss_course_cos  month_year  \n",
      "0                         0.0         0.908572        -0.417728     2019-04  \n",
      "1                         0.0         0.908572        -0.417728     2019-04  \n",
      "2                         0.0         0.908572        -0.417728     2019-04  \n",
      "3                         0.0         0.908572        -0.417728     2019-04  \n",
      "4                         0.0         0.908572        -0.417728     2019-04  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load partitioned Parquet dataset into a Dask DataFrame\n",
    "ddf = dd.read_parquet('finalData.parquet', engine='pyarrow')\n",
    "\n",
    "# Optionally convert to pandas DataFrame\n",
    "ZTBus = ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26c06d6-c233-4a1e-86dd-f3a7198d4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electric_powerDemand                       float32\n",
      "gnss_altitude                              float32\n",
      "gnss_latitude                              float32\n",
      "gnss_longitude                             float32\n",
      "status_doorIsOpen                          float32\n",
      "status_gridIsAvailable                     float32\n",
      "temperature_ambient                        float32\n",
      "traction_brakePressure                     float32\n",
      "traction_tractionForce                     float32\n",
      "busNumber                                    uint8\n",
      "busRoute                                  category\n",
      "timestamp                           datetime64[ns]\n",
      "location_cluster                             uint8\n",
      "wheelSpeed_mean                            float32\n",
      "wheelSpeed_left_right_diff                 float32\n",
      "brake_status                                 uint8\n",
      "itcs_numberOfPassengers_central            float32\n",
      "itcs_numberOfPassengers_range                uint8\n",
      "itcs_numberOfPassengers_spread             float32\n",
      "is_stationary                                uint8\n",
      "gnss_course_stationary_zero_flag             uint8\n",
      "gnss_course_stationary_mean                float32\n",
      "gnss_course_stationary_var                 float32\n",
      "gnss_course_sin                            float32\n",
      "gnss_course_cos                            float32\n",
      "month_year                               period[M]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ZTBus.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1be48b-f67d-41b7-bc64-270cd442cb51",
   "metadata": {},
   "source": [
    "--- Start of the core modelling and in-depth analysis ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3388a6e-ee77-4ead-a835-2f972570e517",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972b1a21-7f46-43bc-8cdb-6253ddcbb6eb",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a18aa-3f55-409e-a31f-6464797131da",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7d2c40-ac5b-48ef-94c6-6ab895ebc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteBehavioralProfiler:\n",
    "    \"\"\"\n",
    "    Bus Route Behavioral Profiling using K-Means clustering\n",
    "    Identifies operational patterns and route personalities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=None, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.kmeans = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.behavioral_features = None\n",
    "        self.route_profiles = None\n",
    "        \n",
    "    def create_behavioral_features(self, df):\n",
    "        \"\"\"\n",
    "        Create route-level behavioral features from raw bus data\n",
    "        \n",
    "        Parameters:\n",
    "        df: DataFrame with columns as specified in your data description\n",
    "        \"\"\"\n",
    "        print(\"Creating behavioral features for routes...\")\n",
    "        \n",
    "        # Group by busRoute and create behavioral profiles\n",
    "        route_behaviors = []\n",
    "        \n",
    "        for route in df['busRoute'].unique():\n",
    "            if pd.isna(route):  # Skip NaN routes\n",
    "                continue\n",
    "                \n",
    "            route_data = df[df['busRoute'] == route]\n",
    "            \n",
    "            # Speed and Movement Behavior\n",
    "            speed_profile = {\n",
    "                'avg_speed': route_data['wheelSpeed_mean'].mean(),\n",
    "                'speed_variability': route_data['wheelSpeed_mean'].std(),\n",
    "                'max_speed': route_data['wheelSpeed_mean'].max(),\n",
    "                'speed_acceleration_events': (route_data['wheelSpeed_mean'].diff() > 2).sum(),\n",
    "                'stationary_frequency': route_data['is_stationary'].mean(),\n",
    "            }\n",
    "            \n",
    "            # Braking and Traction Behavior\n",
    "            braking_profile = {\n",
    "                'avg_brake_pressure': route_data['traction_brakePressure'].mean(),\n",
    "                'brake_intensity': route_data['traction_brakePressure'].std(),\n",
    "                'heavy_braking_events': (route_data['traction_brakePressure'] > route_data['traction_brakePressure'].quantile(0.9)).sum(),\n",
    "                'avg_traction_force': route_data['traction_tractionForce'].mean(),\n",
    "                'traction_variability': route_data['traction_tractionForce'].std(),\n",
    "                'brake_status_changes': route_data['brake_status'].diff().abs().sum(),\n",
    "            }\n",
    "            \n",
    "            # Power and Efficiency Behavior\n",
    "            power_profile = {\n",
    "                'avg_power_demand': route_data['electric_powerDemand'].mean(),\n",
    "                'power_efficiency': route_data['electric_powerDemand'].std(),\n",
    "                'regenerative_braking_freq': (route_data['electric_powerDemand'] < 0).mean(),\n",
    "                'peak_power_events': (route_data['electric_powerDemand'] > route_data['electric_powerDemand'].quantile(0.95)).sum(),\n",
    "            }\n",
    "            \n",
    "            # Passenger Service Behavior\n",
    "            passenger_profile = {\n",
    "                'avg_passenger_load': route_data['itcs_numberOfPassengers_central'].mean(),\n",
    "                'passenger_variability': route_data['itcs_numberOfPassengers_spread'].mean(),\n",
    "                'passenger_range': route_data['itcs_numberOfPassengers_range'].mean(),\n",
    "                'door_opening_frequency': route_data['status_doorIsOpen'].mean(),\n",
    "                'peak_passenger_load': route_data['itcs_numberOfPassengers_central'].max(),\n",
    "            }\n",
    "            \n",
    "            # Environmental and Route Characteristics\n",
    "            environmental_profile = {\n",
    "                'temperature_exposure': route_data['temperature_ambient'].mean(),\n",
    "                'temperature_variability': route_data['temperature_ambient'].std(),\n",
    "                'altitude_variation': route_data['gnss_altitude'].std(),\n",
    "                'avg_altitude': route_data['gnss_altitude'].mean(),\n",
    "                'grid_availability': route_data['status_gridIsAvailable'].mean(),\n",
    "            }\n",
    "            \n",
    "            # Directional Stability and Course Behavior\n",
    "            course_profile = {\n",
    "                'course_stability': 1 - route_data['gnss_course_stationary_var'].mean(),\n",
    "                'directional_changes': route_data['gnss_course_stationary_zero_flag'].sum(),\n",
    "                'route_consistency': 1 - route_data[['gnss_latitude', 'gnss_longitude']].std().mean(),\n",
    "            }\n",
    "            \n",
    "            # Combine all profiles\n",
    "            route_behavior = {\n",
    "                'busRoute': route,\n",
    "                'total_records': len(route_data),\n",
    "                **speed_profile,\n",
    "                **braking_profile,\n",
    "                **power_profile,\n",
    "                **passenger_profile,\n",
    "                **environmental_profile,\n",
    "                **course_profile\n",
    "            }\n",
    "            \n",
    "            route_behaviors.append(route_behavior)\n",
    "        \n",
    "        self.behavioral_features = pd.DataFrame(route_behaviors)\n",
    "        print(f\"Created behavioral profiles for {len(self.behavioral_features)} routes\")\n",
    "        return self.behavioral_features\n",
    "    \n",
    "    def determine_optimal_clusters(self, df=None, max_clusters=15):\n",
    "        \"\"\"\n",
    "        Use elbow method and silhouette analysis to find optimal number of clusters\n",
    "        \n",
    "        Parameters:\n",
    "        df: DataFrame - Raw bus data (optional, will use existing behavioral_features if None)\n",
    "        max_clusters: int - Maximum number of clusters to test\n",
    "        \"\"\"\n",
    "        # Create behavioral features if df provided or if not already created\n",
    "        if df is not None:\n",
    "            self.create_behavioral_features(df)\n",
    "        elif self.behavioral_features is None:\n",
    "            raise ValueError(\"Please provide dataframe or create behavioral features first\")\n",
    "        \n",
    "        # Prepare features for clustering (exclude non-numeric columns)\n",
    "        feature_cols = [col for col in self.behavioral_features.columns \n",
    "                       if col not in ['busRoute', 'total_records']]\n",
    "        X = self.behavioral_features[feature_cols].fillna(0)\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Calculate metrics for different cluster numbers\n",
    "        inertias = []\n",
    "        silhouette_scores = []\n",
    "        k_range = range(2, max_clusters + 1)\n",
    "        \n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=self.random_state, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "            \n",
    "            inertias.append(kmeans.inertia_)\n",
    "            silhouette_scores.append(silhouette_score(X_scaled, cluster_labels))\n",
    "        \n",
    "        # Plot results\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Elbow curve\n",
    "        ax1.plot(k_range, inertias, 'bo-')\n",
    "        ax1.set_xlabel('Number of Clusters')\n",
    "        ax1.set_ylabel('Inertia')\n",
    "        ax1.set_title('Elbow Method for Optimal Clusters')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Silhouette scores\n",
    "        ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "        ax2.set_xlabel('Number of Clusters')\n",
    "        ax2.set_ylabel('Silhouette Score')\n",
    "        ax2.set_title('Silhouette Score vs Number of Clusters')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Suggest optimal number of clusters\n",
    "        optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "        print(f\"Suggested optimal number of clusters: {optimal_k} (highest silhouette score: {max(silhouette_scores):.3f})\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return optimal_k, silhouette_scores, inertias\n",
    "    \n",
    "    def fit_behavioral_clusters(self, df=None, n_clusters=None):\n",
    "        \"\"\"\n",
    "        Fit K-means clustering on behavioral features\n",
    "        \n",
    "        Parameters:\n",
    "        df: DataFrame - Raw bus data (optional, will use existing behavioral_features if None)\n",
    "        n_clusters: int - Number of clusters (optional, will determine optimal if None)\n",
    "        \"\"\"\n",
    "        # Create behavioral features if df provided or if not already created\n",
    "        if df is not None:\n",
    "            self.create_behavioral_features(df)\n",
    "        elif self.behavioral_features is None:\n",
    "            raise ValueError(\"Please provide dataframe or create behavioral features first\")\n",
    "            \n",
    "        if n_clusters:\n",
    "            self.n_clusters = n_clusters\n",
    "        elif self.n_clusters is None:\n",
    "            self.n_clusters, _, _ = self.determine_optimal_clusters()\n",
    "        \n",
    "        # Prepare features\n",
    "        feature_cols = [col for col in self.behavioral_features.columns \n",
    "                       if col not in ['busRoute', 'total_records']]\n",
    "        X = self.behavioral_features[feature_cols].fillna(0)\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Fit K-means\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=self.random_state, n_init=10)\n",
    "        cluster_labels = self.kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        # Add cluster labels to behavioral features\n",
    "        self.behavioral_features['cluster'] = cluster_labels\n",
    "        \n",
    "        print(f\"Successfully clustered {len(self.behavioral_features)} routes into {self.n_clusters} behavioral segments\")\n",
    "        return cluster_labels\n",
    "    \n",
    "    def analyze_cluster_characteristics(self):\n",
    "        \"\"\"\n",
    "        Analyze and interpret the behavioral characteristics of each cluster\n",
    "        \"\"\"\n",
    "        if 'cluster' not in self.behavioral_features.columns:\n",
    "            raise ValueError(\"Please fit clusters first\")\n",
    "        \n",
    "        cluster_summary = {}\n",
    "        feature_cols = [col for col in self.behavioral_features.columns \n",
    "                       if col not in ['busRoute', 'total_records', 'cluster']]\n",
    "        \n",
    "        for cluster_id in sorted(self.behavioral_features['cluster'].unique()):\n",
    "            cluster_data = self.behavioral_features[self.behavioral_features['cluster'] == cluster_id]\n",
    "            \n",
    "            # Calculate mean values for this cluster\n",
    "            cluster_means = cluster_data[feature_cols].mean()\n",
    "            \n",
    "            # Identify top characteristics (features with highest values relative to overall mean)\n",
    "            overall_means = self.behavioral_features[feature_cols].mean()\n",
    "            relative_strength = (cluster_means / overall_means).sort_values(ascending=False)\n",
    "            \n",
    "            cluster_summary[cluster_id] = {\n",
    "                'route_count': len(cluster_data),\n",
    "                'routes': cluster_data['busRoute'].tolist(),\n",
    "                'top_characteristics': relative_strength.head(5).to_dict(),\n",
    "                'mean_values': cluster_means.to_dict()\n",
    "            }\n",
    "            \n",
    "        self.route_profiles = cluster_summary\n",
    "        return cluster_summary\n",
    "    \n",
    "    def visualize_behavioral_profiles(self):\n",
    "        \"\"\"\n",
    "        Create visualizations of the behavioral clusters\n",
    "        \"\"\"\n",
    "        if self.route_profiles is None:\n",
    "            self.analyze_cluster_characteristics()\n",
    "        \n",
    "        # Select key behavioral features for visualization\n",
    "        key_features = [\n",
    "            'avg_speed', 'avg_brake_pressure', 'avg_power_demand', \n",
    "            'avg_passenger_load', 'stationary_frequency', 'door_opening_frequency'\n",
    "        ]\n",
    "        \n",
    "        # Create cluster comparison plot\n",
    "        cluster_means = []\n",
    "        for cluster_id, profile in self.route_profiles.items():\n",
    "            cluster_mean = {**{'cluster': f'Cluster {cluster_id}'}, \n",
    "                          **{feat: profile['mean_values'][feat] for feat in key_features}}\n",
    "            cluster_means.append(cluster_mean)\n",
    "        \n",
    "        cluster_df = pd.DataFrame(cluster_means)\n",
    "        \n",
    "        # Normalize features for better visualization\n",
    "        for feat in key_features:\n",
    "            cluster_df[f'{feat}_norm'] = (cluster_df[feat] - cluster_df[feat].min()) / (cluster_df[feat].max() - cluster_df[feat].min())\n",
    "        \n",
    "        # Create radar chart\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Cluster size distribution\n",
    "        cluster_sizes = [profile['route_count'] for profile in self.route_profiles.values()]\n",
    "        axes[0,0].pie(cluster_sizes, labels=[f'Cluster {i}' for i in range(len(cluster_sizes))], \n",
    "                     autopct='%1.1f%%', startangle=90)\n",
    "        axes[0,0].set_title('Route Distribution Across Clusters')\n",
    "        \n",
    "        # Feature comparison heatmap\n",
    "        heatmap_data = cluster_df.set_index('cluster')[[f'{feat}_norm' for feat in key_features]]\n",
    "        heatmap_data.columns = key_features\n",
    "        sns.heatmap(heatmap_data, annot=True, cmap='RdYlBu_r', ax=axes[0,1], \n",
    "                   cbar_kws={'label': 'Normalized Feature Value'})\n",
    "        axes[0,1].set_title('Behavioral Profile Comparison')\n",
    "        \n",
    "        # Speed vs Power efficiency scatter\n",
    "        axes[1,0].scatter(self.behavioral_features['avg_speed'], \n",
    "                         self.behavioral_features['avg_power_demand'],\n",
    "                         c=self.behavioral_features['cluster'], \n",
    "                         cmap='viridis', alpha=0.7)\n",
    "        axes[1,0].set_xlabel('Average Speed')\n",
    "        axes[1,0].set_ylabel('Average Power Demand')\n",
    "        axes[1,0].set_title('Speed vs Power Demand by Cluster')\n",
    "        \n",
    "        # Passenger load vs Door opening frequency\n",
    "        axes[1,1].scatter(self.behavioral_features['avg_passenger_load'], \n",
    "                         self.behavioral_features['door_opening_frequency'],\n",
    "                         c=self.behavioral_features['cluster'], \n",
    "                         cmap='viridis', alpha=0.7)\n",
    "        axes[1,1].set_xlabel('Average Passenger Load')\n",
    "        axes[1,1].set_ylabel('Door Opening Frequency')\n",
    "        axes[1,1].set_title('Passenger Load vs Service Frequency by Cluster')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def interpret_clusters(self):\n",
    "        \"\"\"\n",
    "        Provide business interpretations of the behavioral clusters\n",
    "        \"\"\"\n",
    "        if self.route_profiles is None:\n",
    "            self.analyze_cluster_characteristics()\n",
    "        \n",
    "        interpretations = {}\n",
    "        \n",
    "        for cluster_id, profile in self.route_profiles.items():\n",
    "            top_chars = profile['top_characteristics']\n",
    "            route_count = profile['route_count']\n",
    "            \n",
    "            # Generate interpretation based on top characteristics\n",
    "            interpretation = f\"Cluster {cluster_id} ({route_count} routes):\\n\"\n",
    "            \n",
    "            # Analyze behavioral pattern\n",
    "            if top_chars.get('avg_speed', 0) > 1.2:\n",
    "                interpretation += \"- HIGH-SPEED routes (highway/express routes)\\n\"\n",
    "            elif top_chars.get('stationary_frequency', 0) > 1.2:\n",
    "                interpretation += \"- STOP-AND-GO routes (urban/local routes)\\n\"\n",
    "            \n",
    "            if top_chars.get('avg_passenger_load', 0) > 1.3:\n",
    "                interpretation += \"- HIGH-CAPACITY routes (major transit corridors)\\n\"\n",
    "            elif top_chars.get('door_opening_frequency', 0) > 1.3:\n",
    "                interpretation += \"- HIGH-FREQUENCY SERVICE routes (many stops)\\n\"\n",
    "            \n",
    "            if top_chars.get('avg_brake_pressure', 0) > 1.2:\n",
    "                interpretation += \"- INTENSIVE BRAKING routes (hilly/congested areas)\\n\"\n",
    "                \n",
    "            if top_chars.get('avg_power_demand', 0) > 1.2:\n",
    "                interpretation += \"- POWER-INTENSIVE routes (challenging terrain/heavy loads)\\n\"\n",
    "            elif top_chars.get('regenerative_braking_freq', 0) > 1.2:\n",
    "                interpretation += \"- ENERGY-EFFICIENT routes (good regenerative braking)\\n\"\n",
    "            \n",
    "            interpretations[cluster_id] = interpretation\n",
    "        \n",
    "        # Print all interpretations\n",
    "        print(\"=== ROUTE BEHAVIORAL CLUSTER INTERPRETATIONS ===\\n\")\n",
    "        for cluster_id, interpretation in interpretations.items():\n",
    "            print(interpretation)\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        return interpretations\n",
    "\n",
    "    def full_pipeline(self, df, n_clusters=None, max_clusters=15, visualize=True):\n",
    "        \"\"\"\n",
    "        Complete end-to-end behavioral clustering pipeline\n",
    "        \n",
    "        Parameters:\n",
    "        df: DataFrame - Raw bus data with required columns\n",
    "        n_clusters: int - Number of clusters (if None, will determine optimal)\n",
    "        max_clusters: int - Maximum clusters to test for optimization\n",
    "        visualize: bool - Whether to create visualizations\n",
    "        \n",
    "        Returns:\n",
    "        dict: Complete analysis results including clusters, profiles, and recommendations\n",
    "        \"\"\"\n",
    "        print(\"=== STARTING ROUTE BEHAVIORAL CLUSTERING PIPELINE ===\\n\")\n",
    "        \n",
    "        # Step 1: Create behavioral features\n",
    "        print(\"Step 1: Creating behavioral features...\")\n",
    "        behavioral_features = self.create_behavioral_features(df)\n",
    "        print(f\"✓ Created {len(behavioral_features)} route behavioral profiles\\n\")\n",
    "        \n",
    "        # Step 2: Determine optimal clusters (if not specified)\n",
    "        if n_clusters is None:\n",
    "            print(\"Step 2: Determining optimal number of clusters...\")\n",
    "            optimal_k, silhouette_scores, inertias = self.determine_optimal_clusters(max_clusters=max_clusters)\n",
    "            n_clusters = optimal_k\n",
    "            print(f\"✓ Optimal clusters determined: {optimal_k}\\n\")\n",
    "        else:\n",
    "            print(f\"Step 2: Using specified number of clusters: {n_clusters}\\n\")\n",
    "        \n",
    "        # Step 3: Fit clustering model\n",
    "        print(\"Step 3: Fitting K-means clustering...\")\n",
    "        cluster_labels = self.fit_behavioral_clusters(n_clusters=n_clusters)\n",
    "        print(f\"✓ Successfully clustered routes into {n_clusters} segments\\n\")\n",
    "        \n",
    "        # Step 4: Analyze clusters\n",
    "        print(\"Step 4: Analyzing cluster characteristics...\")\n",
    "        cluster_summary = self.analyze_cluster_characteristics()\n",
    "        print(\"✓ Cluster analysis complete\\n\")\n",
    "        \n",
    "        # Step 5: Generate business interpretations\n",
    "        print(\"Step 5: Generating business interpretations...\")\n",
    "        interpretations = self.interpret_clusters()\n",
    "        print(\"✓ Business interpretations generated\\n\")\n",
    "        \n",
    "        # Step 6: Create visualizations\n",
    "        if visualize:\n",
    "            print(\"Step 6: Creating visualizations...\")\n",
    "            self.visualize_behavioral_profiles()\n",
    "            print(\"✓ Visualizations complete\\n\")\n",
    "        \n",
    "        # Compile complete results\n",
    "        results = {\n",
    "            'behavioral_features': self.behavioral_features,\n",
    "            'cluster_labels': cluster_labels,\n",
    "            'cluster_profiles': self.route_profiles,\n",
    "            'interpretations': interpretations,\n",
    "            'model_metrics': {\n",
    "                'n_clusters': self.n_clusters,\n",
    "                'total_routes': len(behavioral_features),\n",
    "                'silhouette_score': silhouette_score(\n",
    "                    self.scaler.transform(behavioral_features[[col for col in behavioral_features.columns \n",
    "                                                              if col not in ['busRoute', 'total_records', 'cluster']]].fillna(0)),\n",
    "                    cluster_labels\n",
    "                ) if hasattr(self, 'scaler') else None\n",
    "            },\n",
    "            'route_assignments': dict(zip(behavioral_features['busRoute'], cluster_labels))\n",
    "        }\n",
    "        \n",
    "        print(\"=== PIPELINE COMPLETE ===\")\n",
    "        print(f\"Successfully analyzed {len(behavioral_features)} routes across {self.n_clusters} behavioral clusters\")\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c101b358-4330-41cb-afa1-4af826f8f168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExample of how to use the RouteBehavioralProfiler\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    Example of how to use the RouteBehavioralProfiler\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the profiler\n",
    "    # profiler = RouteBehavioralProfiler()\n",
    "    \n",
    "    # Load your data (replace with actual data loading)\n",
    "    # df = pd.read_csv('your_bus_data.csv')\n",
    "    \n",
    "    # Step 1: Create behavioral features from raw data\n",
    "    # behavioral_features = profiler.create_behavioral_features(df)\n",
    "    \n",
    "    # Step 2: Determine optimal number of clusters\n",
    "    # optimal_k, silhouette_scores, inertias = profiler.determine_optimal_clusters()\n",
    "    \n",
    "    # Step 3: Fit the clustering model\n",
    "    # cluster_labels = profiler.fit_behavioral_clusters(n_clusters=optimal_k)\n",
    "    \n",
    "    # Step 4: Analyze cluster characteristics\n",
    "    # cluster_summary = profiler.analyze_cluster_characteristics()\n",
    "    \n",
    "    # Step 5: Visualize the results\n",
    "    # profiler.visualize_behavioral_profiles()\n",
    "    \n",
    "    # Step 6: Get business interpretations\n",
    "    # interpretations = profiler.interpret_clusters()\n",
    "    \n",
    "    #print(\"Route Behavioral Profiling Pipeline Ready!\")\n",
    "    #print(\"Load your data and uncomment the steps to run the analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e268a7c-c77e-451f-86bf-e6c4e141c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = RouteBehavioralProfiler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6d0c5-5518-4a99-908c-b4b6b67079ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_features = profiler.create_behavioral_features(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
